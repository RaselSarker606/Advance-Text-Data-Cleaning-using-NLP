{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoZJzFcmh7YU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e8a3b5b-24ff-42ef-ca33-97e12974fcc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = ['The NLP Sentences @algorithm **processed the text removing stopwords such as the and is, handling punctuation marks, %%S like commas and periods addressing alphanumeric values like abc123 applying stemming to reduce words like jumping to jump, converting uppercase letters to lowercase and dealing with special characters such as @ and &']"
      ],
      "metadata": {
        "id": "GDP8gMSri1c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: 1\n",
        "\n",
        "##Convert to lower case:\n",
        "\n",
        "This means that words like \"Hello\", \"hello\", and \"HELLO\" are treated as the same word, simplifying comparisons and matching operations"
      ],
      "metadata": {
        "id": "b8QjiLUZjkk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "lower = [k.lower() for k in data]\n",
        "print(lower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "popuZhIQi1ib",
        "outputId": "8d4ef98c-fc08-47d1-af90-82d9e1abf2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the nlp sentences @algorithm **processed the text removing stopwords such as the and is, handling punctuation marks, %%s like commas and periods addressing alphanumeric values like abc123 applying stemming to reduce words like jumping to jump, converting uppercase letters to lowercase and dealing with special characters such as @ and &']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: 2\n",
        "##tokenization:\n",
        "\n",
        "\n",
        "The word_tokenize function from the NLTK (Natural Language Toolkit) library is commonly used for tokenizing text into words or word-like units."
      ],
      "metadata": {
        "id": "QR0NXOR2mYAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "token_lower = [word_tokenize(k) for k in lower]\n",
        "print(token_lower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVY5flaii1ly",
        "outputId": "d708f571-2597-422c-db34-a03a42054e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['the', 'nlp', 'sentences', '@', 'algorithm', '*', '*', 'processed', 'the', 'text', 'removing', 'stopwords', 'such', 'as', 'the', 'and', 'is', ',', 'handling', 'punctuation', 'marks', ',', '%', '%', 's', 'like', 'commas', 'and', 'periods', 'addressing', 'alphanumeric', 'values', 'like', 'abc123', 'applying', 'stemming', 'to', 'reduce', 'words', 'like', 'jumping', 'to', 'jump', ',', 'converting', 'uppercase', 'letters', 'to', 'lowercase', 'and', 'dealing', 'with', 'special', 'characters', 'such', 'as', '@', 'and', '&']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: 3\n",
        "##Punctuation Removal\n",
        "Removing punctuation involves stripping out characters like periods, commas, exclamation marks, question marks, and so on from a piece of writing."
      ],
      "metadata": {
        "id": "dgUhRT77pRWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "regEx = re.compile('[%s]' %re.escape(string.punctuation))\n",
        "#print(regEx)\n",
        "\n",
        "punk_token_lower = []\n",
        "\n",
        "for k in token_lower:\n",
        "  review = []\n",
        "  for j in k:\n",
        "    x = regEx.sub(U'',j)\n",
        "    #U'' is an empty Unicode string\n",
        "    if not review == U'':\n",
        "      review.append(x)\n",
        "  punk_token_lower.append(review)\n",
        "\n",
        "print(punk_token_lower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5o6o4JKmjDZ",
        "outputId": "2ce4a076-57aa-4a0b-ff86-f5376f8ef159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['the', 'nlp', 'sentences', '', 'algorithm', '', '', 'processed', 'the', 'text', 'removing', 'stopwords', 'such', 'as', 'the', 'and', 'is', '', 'handling', 'punctuation', 'marks', '', '', '', 's', 'like', 'commas', 'and', 'periods', 'addressing', 'alphanumeric', 'values', 'like', 'abc123', 'applying', 'stemming', 'to', 'reduce', 'words', 'like', 'jumping', 'to', 'jump', '', 'converting', 'uppercase', 'letters', 'to', 'lowercase', 'and', 'dealing', 'with', 'special', 'characters', 'such', 'as', '', 'and', '']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step: 4\n",
        "#Removing Stopwords:\n",
        "Stopwords are commonly occurring words that are necessary for the structure of sentences but often don't contribute much to the overall meaning or context of the text and also Don't carry significant meaning"
      ],
      "metadata": {
        "id": "ifpIvPMQD4tI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "#print(stopwords.words('english'))\n",
        "\n",
        "\n",
        "stopword_punk_token_lower = []\n",
        "\n",
        "for k in punk_token_lower:\n",
        "  remove_stopword = []\n",
        "  for j in k:\n",
        "    if not j in stopwords.words('english'):\n",
        "      remove_stopword.append(j)\n",
        "  stopword_punk_token_lower.append(remove_stopword)\n",
        "\n",
        "print(stopword_punk_token_lower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-OppB4pD4fH",
        "outputId": "e4483741-e85c-4da4-b8f6-228e770e2604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['nlp', 'sentences', '', 'algorithm', '', '', 'processed', 'text', 'removing', 'stopwords', '', 'handling', 'punctuation', 'marks', '', '', '', 'like', 'commas', 'periods', 'addressing', 'alphanumeric', 'values', 'like', 'abc123', 'applying', 'stemming', 'reduce', 'words', 'like', 'jumping', 'jump', '', 'converting', 'uppercase', 'letters', 'lowercase', 'dealing', 'special', 'characters', '', '']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: 5\n",
        "#Stemming and Lemmatization:\n",
        "\n",
        "Stemming is core meaning of a word and lemmatization is identify the dictionary form of a word"
      ],
      "metadata": {
        "id": "wEMBhksmGHYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "wordnet = WordNetLemmatizer()\n",
        "\n",
        "stemLem_stopword_punk_token_lower = []\n",
        "\n",
        "for k in stopword_punk_token_lower:\n",
        "  stemLem =[]\n",
        "  for j in k:\n",
        "    #stemLem.append(porter.stem(j))\n",
        "    stemLem.append(wordnet.lemmatize(j))\n",
        "  stemLem_stopword_punk_token_lower.append(' '.join(stemLem))\n",
        "print(stemLem_stopword_punk_token_lower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFM85j8YGGoL",
        "outputId": "31dd4a19-b18b-45bd-8f44-7772574e6cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nlp sentence  algorithm   processed text removing stopwords  handling punctuation mark    like comma period addressing alphanumeric value like abc123 applying stemming reduce word like jumping jump  converting uppercase letter lowercase dealing special character  ']\n"
          ]
        }
      ]
    }
  ]
}